---
title: Mini Proyecto de Análisis Exploratorio de Datos
author:
  - name: Nicolás Camañes Antolín
  - name: Rubén Castillo Carrasco
  - name: Erik González Soler
  - name: Jesús Martínez Leal

# document options
journal: notspecified
type: article

# front matter
simplesummary: |
  En este proyecto de Análisis Exploratorio de Datos se explora un conjunto de datos real con el fin de obtener valiosas perspectivas y conclusiones.
abstract: |
  
  A single paragraph of about 200 words maximum. For research articles, 
  abstracts should give a pertinent overview of the work. We strongly encourage
  authors to use the following style of structured abstracts, but without 
  headings: 1) Background: Place the question addressed in a broad context and
  highlight the purpose of the study; 2) Methods: Describe briefly the main
  methods or treatments applied; 3) Results: Summarize the article's main 
  findings; and 4) Conclusion: Indicate the main conclusions or interpretations. 
  The abstract should be an objective representation of the article, it must not 
  contain results which are not presented and substantiated in the main text and 
  should not exaggerate the main conclusions.
  
# back matter
keywords: |
  Análisis exploratorio de datos; Patrones en datos; Encuesta de población; Limpieza de datos
acknowledgement: |
  Es necesario mostrar nuestro agradecimiento a ValgrAI por el apoyo en el pago de la matrícula para el Máster en Ciencia de Datos (UV). Además, no nos podemos olvidar del profesorado que nos permitirá formarnos en este ámbito.
authorcontributions: |
  Aquí tenemos que poner más o menos lo que ha participado cada uno.
abbreviations:
  - short: AED
    long: Análisis Exploratorio de Datos
    
bibliography: mybibfile.bib
appendix: appendix.tex
endnotes: false
output: 
  rticles::mdpi_article:
    extra_dependencies: longtable
---

# Introducción.

El conjunto de datos que se utiliza para el análisis pertenece al Instituto Nacional de Estadística (INE). En concreto, pertenece a una encuesta realizada a la población en el año 2021 que tiene como propósito el proporcionar información detallada sobre personas, viviendas y edificios que no puede obtenerse a través de registros administrativos. En nuestro caso, hemos decidido hacer la exploración en su mayoría de la parte relacionada a cuestiones que se les hizo a adultos (personas de 16 años o más). Para agregar más variables de interés se escogieron algunas de otro conjunto de datos, también de esta encuesta, hecho a todos los integrantes de la vivienda y no solo a adultos. El enlace a los ficheros de microdatos se encuentra disponible en el siguiente [enlace](https://www.ine.es/dyngs/INEbase/es/operacion.htm?c=Estadistica_C&cid=1254736177092&menu=resultados&idp=1254735572981#!tabs-1254736195790).

## Carga de librerías y datos necesarios para el análisis

```{r setup, cache = F, echo = F, message = F, warning = F, tidy = F}
# Configuración general de chunks
library(knitr)
options(width = 100)
knitr::opts_chunk$set(echo = F, message = F, error = F, warning = F, comment = NA, dpi = 100, tidy = F, cache.path = '.cache/', fig.path = './figure/', include = F)
```

Primeramente, se cargan todas las librearías necesarias en las diferentes fases del proyecto.

```{r librerias, message = F, include = T, echo = F}
# Carga de librerías necesarias con pacman
library(pacman)
pacman::p_load(readr, stringr, tidyr, dplyr, readxl, ggplot2, forcats, haven, kableExtra, VIM, e1071, ggstatsplot, gridExtra, reshape2)
```

A continuación, se realiza la carga del conjunto de datos, presente tanto en *.txt* como *.csv* en la carpeta *./data* incluida en el repositorio del proyecto. Asimismo, se carga el fichero .xlsx que nos muestra el diseño de registro y valores válidos de las variables. Este fichero será especialmente útil, puesto que permitirá una automatización para convertir el conjunto de datos, que actualmente se encuentra en estado Raw data, a Technically correct data, teniendo cada variable su tipo correspondiente.

```{r extraccion_dataset_csv}
ruta_csv <- "data/ECEPOVadultos_2021.csv"
df_1 <- read_delim("data/ECEPOVadultos_2021.csv", 
    delim = "\t", escape_double = FALSE, 
    col_types = cols(ESTUDIOS = col_double(), 
        CAMPO = col_double()), trim_ws = TRUE)
```

```{r lectura_dataset_readLines, eval = FALSE}
ruta_txt <- "./data/md_ECEPOVadultos_2021.txt"
lines <- readLines(ruta_txt)

# Función para sacar las subcadenas en cada línea del .txt

extract_substrings <- function(line, start_position, length) {
  substrings <- character(length(start_position))
  
  for (i in seq_along(start_position)) {
    start <- start_position[i]
    end <- start + length[i] - 1
    substrings[i] <- substr(line, start, end)
  }
  
  return(substrings)
}

# Guardaremos las substrings en una matriz por eficiencia computacional

num_lines <- length(lines)
num_variables <- length(excel_info_1$Variable)
substring_matrix <- matrix("", nrow = num_lines, ncol = num_variables)

# Extraer las subcadenas para todas las líneas y guardarlas en las filas de la matriz

for (i in 1:num_lines) {
  substring_matrix[i, ] <- extract_substrings(lines[i], excel_info_1$Posición, excel_info_1$Longitud)
}

# Conversión al dataframe desde la matriz

df_1 <- as.data.frame(substring_matrix)
colnames(df_1) <- excel_info_1$Variable

```

```{r lectura_diseno}
ruta_excel <- "data/dr_ECEPOVadultos_2021.xlsx"
excel_info_1 <- read_excel(ruta_excel, sheet = "Diseño", range = "A2:H50", col_names = TRUE)

# Almacenamiento de distintas hojas del excel para optimizar el código
Tablas1 <- read_excel(ruta_excel, sheet = "Tablas1", range = "A4:C63", col_names = TRUE)
Tablas2 <- read_excel(ruta_excel, sheet = "Tablas2", range = "A4:C112", col_names = TRUE)
Tablas3 <- read_excel(ruta_excel, sheet = "Tablas3", range = "A4:C48", col_names = TRUE)
```

A pesar de que resultó de gran utilidad el fichero que ofrecía INE para la transformación de las variables a un tipo correspondiente, surgieron algunos fallos que se debieron solventar de manera manual. Determinadas variables no fueron adecuadamente codificadas por parte del INE, de tal forma que fue necesario que modificar ligeramente el fichero .xlsx. Concretamente, algunos diccionarios de variables en los que no terminaba de estar correctamente determinado el código (lo que sería el level en un factor). El problema presentado (en algunas variables) consistía, básicamente, en que aparecía "01" en lugar de "1", valor recogido en las observaciones.

```{r conversion_dataset}
# Cambio manual por datos mal introducidos "2 " --> "2" para la posterior lectura con el diccionario

manual_change <- c("ESTUDIOS", "CAMPO", "NDESPLA", "MTRANSPOR_1", "MTRANSPOR_2")

df_1 <- df_1 %>%
  mutate(across(all_of(manual_change), ~ str_remove_all(., " ")))

# Codificamos los NA de la variable NHIJOS como 0, ya que nos será útil más tarde esta interpretación

df_1 <- df_1 %>%
  mutate(NHIJOS = ifelse(is.na(NHIJOS), 0, NHIJOS))

# Conversión de las variables correspondientes a tipo numérico según indica INE

dic_tipo <- excel_info_1$Tipo

df_1 <- df_1 %>%
  mutate(across(which(dic_tipo == "N"), as.numeric)) %>%
  mutate()

# Transformación a factores de las variables pertinentes usando el fichero que ofrece INE

excel_dic <- excel_info_1 %>%
  filter(!is.na(`Diccionario de la variable`))

dic_vars <- excel_dic$Variable
dic_var <- excel_dic$`Diccionario de la variable`
dic_table <- excel_dic$`Diccionario ubicado en la hoja…`

## bucle donde se irán convirtiendo a factor de manera iterativa aquellas variables que nos indique el fichero del INE

for (i in seq_along(dic_vars)) {
  
  dataframe_name <- dic_table[i]  
  df_table <- get(dataframe_name)
  positions <- which(df_table == dic_var[i], arr.ind = TRUE) # obtener posición donde se encuentra la palabra del diccionario 
  
  if (length(positions) > 0) {
    
    fila_start <- positions[1]
    columna_start <- positions[2]
    
    fila_end <- min(which(is.na(df_table[(fila_start + 2):nrow(df_table), columna_start]), arr.ind = TRUE)[1]) + fila_start

    levels <- df_table[(fila_start + 2):fila_end, columna_start]
    labels <- df_table[(fila_start + 2):fila_end, columna_start + 1]
    
    # conversión a tipo vector para aplicar debajo factor()
    levels <- unlist(levels[[1]])
    labels <- unlist(labels[[1]])
  }
  
  df_1 <- df_1 %>%
      mutate_at(vars(dic_vars[i]), ~factor(., levels = levels, labels = labels)) 
}
```

Una vez está hecha la conversión del dataset que contaba con un mayor número de variables se procede a hacer una unión con el otro dataset mencionado anteriormente, solo utilizando algunas variables de interés como SEXO o EDAD.


```{r seleccion_columnas}
columnas_a_leer <- c("IDEN", "NPV", "FACTOR", "SEXO", "EDAD", "NACIM", "PNACIM")
df_2 <- read_dta("./data/ECEPOVhogar_2021.dta", col_select = columnas_a_leer)
```

Las variables SEXO, NACIM y PNACIM de este nuevo dataset deben ser convertidas a sus tipos correspondientes, por lo que se hace uso de la información que proporciona el INE sobre dichas variables.

```{r lectura_diseno_2}
ruta_excel_2 <- "data/dr_ECEPOVhogar_2021.xlsx"
excel_info_2 <- read_excel(ruta_excel_2, sheet = "Diseño", range = "A2:H162", col_names = TRUE)

# Cogemos los diccionarios manualmente puesto que solo tenemos 3 variables y el proceso es más eficiente en lectura

T_SEXO <- read_excel(ruta_excel_2, sheet = "Tablas2", range = "A6:B8", col_names = TRUE)
T_NACIM <- read_excel(ruta_excel_2, sheet = "Tablas2", range = "A26:B28", col_names = TRUE)
T_PAIS <- read_excel(ruta_excel_2, sheet = "Tablas1", range = "A74:B276", col_names = TRUE)
```

```{r conversion_dataset_2}
df_2 <- df_2 %>%
  mutate(SEXO = factor(SEXO, levels = T_SEXO$Código, labels = T_SEXO$Descripción)) %>%
  mutate(NACIM = factor(NACIM, levels = T_NACIM$Código, labels = T_NACIM$Descripción)) %>%
  mutate(PNACIM = factor(PNACIM, levels = T_PAIS$Código, labels = T_PAIS$Descripción))
```

Por último, para lograr la unión de ambos datasets, se emplea la función *merge* utilizando las variables de identificación IDEN, NPV y FACTOR, de tal manera que podamos establecer una relación unívoca entre los adultos presentes en el primer y segundo dataset.

```{r union_datasets}
df_merged <- merge(df_1, df_2[, c("IDEN", "NPV", "FACTOR", "EDAD", "SEXO", "NACIM", "PNACIM")], by = c("IDEN", "NPV", "FACTOR"), all.x = TRUE)
```

## Características generales de los datos

Es posible hacerse una idea rápida de cuáles son los datos pertenecientes al dataframe, *df*, haciendo uso de la función *glimpse*, perteneciente a la librería *dplyr*. 

```{r glimpse}
dplyr::glimpse(df_merged, width = 60)
```

Se observa que es un dataset con total de 361934 observaciones y con 52 variables, lo cual es mucho más de lo que se puede abarcar en un análisis exploratorio como el que se requiere en este trabajo.

Tras un análisis de las variables en *dr_ECEPOVadultos_2021.xlsx* y  
*dr_ECEPOVhogar_2021.xlsx*, se ha considerado que muchas de las variables no nos otorgarán interés para el análisis que particularmente se desea aplicar, por lo que se seleccionaran aquellasvariables consideradas más relevantes.


```{r variables_usadas, include = T}
data_info <- data.frame(
  Variable = c(
    "IDQ_PV", "TAM_MUNI", "EC", "EDADEC", "ESTUDIOS", "ANOESTUD",
    "EDADESTUD", "CAMPO", "SITLAB", "SATISTIEMP", "COMPRAINT", "HIJOS",
    "NHIJOS", "TDOMEST", "SEXO", "EDAD", "NACIM", "PNACIM"
  ),
  Descripción = c(
    "Código de la provincia de residencia.",
    "Tamaño del municipio.",
    "Estado civil legal.",
    "Edad de adquisición del estado civil legal.",
    "Nivel de estudios alcanzado.",
    "Año que alcanzó su mayor nivel de estudios.",
    "Edad a la que alcanzó su mayor nivel de estudios.",
    "Campo de los estudios.",
    "Situación laboral durante la última semana.",
    "Grado de satisfacción en el tiempo de desplazamiento al trabajo.",
    "Realización de compras por internet en el último mes.",
    "Tenencia de hijos.",
    "Número total de hijos.",
    "Grado de participación en las tareas domésticas del hogar.",
    "Sexo de la persona.",
    "Edad de la persona.",
    "Lugar de nacimiento de la persona (España u otro sitio).",
    "País de nacimiento exacto de la persona."
  )
)

knitr::kable(data_info, format = "latex",
             booktabs = TRUE, 
             caption = "Variables de interés para el estudio.", 
             align = 'ccc', centering = FALSE,
             table.envir = "table", position = "H")
```

```{r seleccion_variables}
var_interes <- c("IDQ_PV", "TAM_MUNI", "SEXO", "EDAD", "NACIM", "PNACIM", "EC", "EDADEC", "ESTUDIOS", "ANOESTUD", "EDADESTUD", "CAMPO", "SITLAB", "SATISTIEMP", "COMPRAINT", "NHIJOS", "HIJOS", "TDOMEST")
  
df <- df_merged %>%
  dplyr::select(var_interes)
```

```{r glimpse_reducido}
glimpse(df, width = 60)
```

Seguidamente, mediante la función *summary* obtenemos información acerca de las características de cada columna del dataset. 

```{r summary}
summary(df)
```

Una modificación de la función summary que incluye algo menos de información, pero que nos será útil al no haber tanta saturación aparece a continuación.

```{r funcion_sumario, include = FALSE}
SumarioDatos <- function(data = data, digitos = 3, max_topLevel_length = 47) {
  type <- sapply(data, class)
  levels <- sapply(data, function(x) { length(unique(x)) })
  topLevel <- sapply(data, function(x) {
    t <- table(x)
    colnames(t(which.max(t)))
  })

  # Truncate topLevel and add "..." if it exceeds the maximum length
  topLevel <- ifelse(nchar(topLevel) > max_topLevel_length, paste0(substr(topLevel, 1, max_topLevel_length - 3), "..."), topLevel)

  topCount <- sapply(data, function(x) { max(table(x)) })
  topFrac <- sapply(data, function(x, digitos) {
    t <- table(x)
    (max(t) / sum(t))
  }) %>% round(digits = digitos)

  missFrac <- sapply(data, function(x) { sum(is.na(x) == TRUE) / length(x) }) %>%
    round(digits = digitos)

  sumario <- data.frame(
    variable = colnames(data),
    type = type,
    levels = levels,
    topLevel = topLevel,
    topCount = topCount,
    topFrac = topFrac,
    missFrac = missFrac
  )

  rownames(sumario) <- NULL
  return(sumario)
}
```

```{r kable_sumario, include = T}
kable_res <- knitr::kable(SumarioDatos(data = df), format = "latex",
             booktabs = TRUE, 
             caption = "Información relevante acerca de las variables de estudio.", 
             align = 'ccc', centering = FALSE,
             table.envir = "table", position = "H",
             tabular.environment = "tabularx")

kable_styling(kable_res, font_size = 7, position = "left")
```

### Datos faltantes

Una representación precisa de cómo se distribuyen los *missing values* por nuestro conjunto de datos lo otorga la librería *VIM* con la función *aggr*. Se han representado solamente aquellas variables que cuentan con algún NA para facilitar la visualización. En el siguiente gráfico puede observarse tanto la proporción total de valores faltantes en dichas variables individualmente (izquierda), como una serie de combinaciones posibles entre ellas de valores faltantes. 

Así, encontramos por ejemplo que la combinación de NA en (SATISTIEMP, ANOESTUD, EDADESTUD, CAMPO) cuenta con una proporción del 27.9 % de los datos totales.

```{r missing_values, include = T, fig.width = 5.8, fig.height = 4, fig.align = "left"}
aggr_result <- capture.output({
  df %>%
    select_if(~ anyNA(.)) %>%
    aggr(prop = TRUE, numbers = TRUE, sortVars = TRUE, sortCombs = TRUE, cex.axis = 0.6, cex.lab = 0.7, digits = 1, gap = 2, cex.numbers = 0.6, plot = TRUE)
})

# Mostrar solo el plot sin el data.frame para el Rmd
invisible(aggr_result)
```
# Exploración inicial / visualización

Una vez hemos asegurado que nuestros datos estén en la estructura de data.frame, tengan los valores correctamente etiquetados y estén almacenados con el tipo correcto, podemos empezar a buscar posibles patrones en las instancias o entre las características.

## Análisis univariante.

Distinguiremos el análisis entre las variables de tipo numérico y las de tipo categórica (factor) presentes, ya que ciertos estadísticos descriptivos (como por ejemplo la media) carecen de sentido en las pertenecientes al último tipo.

### Variables de tipo numérico

Se ha creado una función para poder obtener diferentes estadísticos de las variables numéricas. Dichos estadisticos se representan mediante la siguiente tabla.

```{r summarise_numeric}
df_sumnum <- df %>%
  select_if(is.numeric) %>%
  summarise_all(list(
    Media = ~round(mean(., na.rm = TRUE), 2), 
    Mediana = ~round(median(., na.rm = TRUE), 2),
    DesvEst = ~round(sd(., na.rm = TRUE), 2),
    Asimetria = ~round(skewness(., na.rm = TRUE), 2),
    Curtosis = ~round(kurtosis(., na.rm = TRUE), 2)
  )) %>%
  pivot_longer(cols = everything()) %>%
  tidyr::separate(col = name, into = c("Variable", "Estadístico")) %>%
  pivot_wider(names_from = "Estadístico", values_from = "value")
```

```{r kable_summarise_numeric, include = TRUE}
kable_sumnum <- knitr::kable(df_sumnum, format = "latex",
             booktabs = TRUE, 
             caption = "Estadísticos de variables numéricas", 
             align = 'ccc', centering = FALSE,
             table.envir = "table", position = "H",
             tabular.environment = "tabularx")

kable_styling(kable_sumnum, font_size = 8, position = "center", full_width = TRUE)
```

Para completar el análisis univariante de las variables numéricas, se ha generado el siguiente gráfico. Que se corresponde con el histograma de la variable *EDAD* y con la correspondiente densidad de los datos.

```{r echo=FALSE, include=TRUE}
# Calcular la media y la desviación estándar de la variable "EDAD"

media_edad <- mean(df$EDAD)
desviacion_edad <- sd(df$EDAD)

# Crear el histograma de densidad y superponer la curva gaussiana

p_edad_histogram_density <- ggplot(df, aes(x = EDAD)) +
  geom_histogram(aes(y = after_stat(density)), binwidth = 1, fill = "lightblue", color = "black") +
  labs(
    title = "Distribución de edades en la encuesta",
    x = "Edad / años",
    y = "Densidad"
  ) +
  theme_minimal() +
  scale_x_continuous(breaks = seq(15, 120, by = 10)) +
  
  # Superponer la curva gaussiana 
  
  stat_function(
    fun = dnorm,  # Función de densidad de probabilidad normal
    args = list(mean = media_edad, sd = desviacion_edad),
    color = "red",
    size = 1
  )

p_edad_histogram_density
```
Mediante el gráfico anterior, se aprecia que las edades más fracuentes en el dataset van de 40 a 60 años. 

### Variables de tipo categórico

A diferencia de las variables numérica, en las variables categóricas no es posible obtener muchos estadísticos. El más común es la moda, que se corresponde con la columna *topCount* de la tabla 2.

Otra información que se puede analizar en el análisis univariante de una variable categórica es la frecuencia de aparición de cada una de las categorías. Esto es posible representarlo visualmente mediante un gráfico de barras. Es por ello que se ha realizado dicho gráfico para explicar los datos de la variable *SITLAB*

```{r}
frecuencias <- data.frame(Situacion = df$SITLAB) %>% count(Situacion)
```


```{r echo=FALSE, include=TRUE}
ggplot(frecuencias, aes(x = reorder(Situacion, -n), y = n, fill = n)) +
  geom_bar(stat = "identity",
           col = "black") +
  labs(title = "Diagrama de Barras para representar la Situación Laboral (SITLAB)",
       x = "Categoría",
       y = "Frecuencia") +
  theme(axis.text.x = element_text(angle = 70, hjust = 1)) +
  scale_fill_gradient(low = "lightblue", high = "darkblue")
```
Tal y como se aprecia en el gráfico, en el momento en que se realizó la encuesta, predominaban claramente las personas ocupadas a tiempo completo. Seguidas de las jubiladas.

## Análisis bivariante

Como su nombre indica, la fase de análisis bivariante, consiste en la búsqueda de relación entre dos variables. Para ello existen diferentes formas de representación, en función del tipo de variables que se esté tratando tratando.

### Gráficos

<!-- Númerica - Númerica -->
En primer lugar, se generará un gráfico para var la relación entre la edad de las personas y su grado de satisfacción con el tiempo de desplazamiento hasta su puesto de trabajo.

```{r}
ggplot(df, aes(x = EDADEC, y = NHIJOS))+geom_point()
```

<!-- Númerica - Categórica -->

```{r edad_by_sexo, echo=FALSE, include = TRUE}
p_edad <- ggplot(df, aes(x = EDAD, color = SEXO)) +
  geom_freqpoly(binwidth = 1) +
  labs(
    title = "Distribución de edades en la encuesta",
    x = "Edad / años",
    y = "Frecuencia"
  ) +
  scale_color_manual(values = c("Hombre" = "blue", "Mujer" = "red")) +
  theme_minimal() +
  scale_x_continuous(breaks = seq(15, 120, by = 10))

p_edad
```

```{r echo=FALSE, include=TRUE}
ggplot(df, aes(x = TDOMEST, y = EDAD, colour = SEXO)) + geom_point(size = 0.25) + geom_jitter() + theme_minimal() + scale_x_discrete(labels = c("Todas las tareas", "La mitad de las tareas", "Pocas tareas", "Ninguna tarea"))
```

<!-- Categórica - Categórica -->

### Caracterización

<!-- Mapa de correlaciones -->

```{r}
# Seleccionamos las variables numéricas del dataframe
df_numericas <- df[sapply(df, is.numeric)]
# Eliminamos las instancias que contengan NAs, ya que esto producirá errores en las correlaciones
df_numericas_sin_nas <- na.omit(df_numericas)
normalizados <- scale(df_numericas_sin_nas)
# Obtenemos la matriz de correlación
corr_mat <- round(cor(as.data.frame(normalizados)),2)
```

```{r}
# Get upper triangle of the correlation matrix
get_upper_tri <- function(corr_mat){
  corr_mat[lower.tri(corr_mat)]<- NA
  return(corr_mat)
}
```

```{r}
upper_tri <- get_upper_tri(corr_mat)
melted_upper_tri <- melt(upper_tri, na.rm = TRUE)
```

```{r echo=FALSE, include=TRUE}
ggplot(data = melted_upper_tri, aes(Var2, Var1, fill = value))+
 geom_tile(color = "white")+
 scale_fill_gradient2(low = "blue", high = "red", mid = "white", 
   midpoint = 0, limit = c(-1,1), space = "Lab", 
   name="Pearson\nCorrelation") +
  theme_minimal()+ 
 theme(axis.text.x = element_text(angle = 45, vjust = 1, 
    size = 12, hjust = 1))+
 coord_fixed() + 
  geom_text(aes(Var2, Var1, label = value), color = "black", size = 4) +
theme(
  axis.title.x = element_blank(),
  axis.title.y = element_blank(),
  panel.grid.major = element_blank(),
  panel.border = element_blank(),
  panel.background = element_blank(),
  axis.ticks = element_blank(),
  legend.justification = c(1, 0),
  legend.position = c(0.6, 0.7),
  legend.direction = "horizontal")+
  guides(fill = guide_colorbar(barwidth = 7, barheight = 1,
                title.position = "top", title.hjust = 0.5))

```
<!-- Cross Table Variables categóricas -->

```{r}
library(crosstable)
ct1 = crosstable(df, c(SITLAB, COMPRAINT, TDOMEST), by=HIJOS, total="both", percent_pattern="{n} ({p_row}/{p_col})", percent_digits=0, funs=mean, effect=TRUE) %>% as_flextable()
ct1
```


### Resto de cosas hechas

```{r}
# Crea un QQ plot para la variable "EDAD"

qqplot_edad <- ggplot(df, aes(sample = EDAD, color = SEXO)) +
  stat_qq() +
  stat_qq_line() +
  ggtitle("QQ Plot para la variable EDAD") +
  xlab("Cuantiles teóricos") +
  ylab("Cuantiles observados")

qqplot_edad
```

https://ggplot2.tidyverse.org/reference/geom_qq.html

```{r numhijos_by_nacionalidad_separado}
df_espana <- df %>%
  filter(NACIM == "España") %>%
  group_by(NHIJOS) %>%
  summarize(RelativeFrequency = n() / nrow(.))

df_otro_pais <- df %>%
  filter(NACIM == "Otro país") %>%
  group_by(NHIJOS) %>%
  summarize(RelativeFrequency = n() / nrow(.))

y_limits <- range(0, max(max(df_espana$RelativeFrequency), max(df_otro_pais$RelativeFrequency)))

p_numhijos_espana <- ggplot(df_espana, aes(x = NHIJOS, y = RelativeFrequency)) +
  geom_bar(stat = "identity", fill = "blue") +
  labs(
    title = "Número de hijos (España)",
    x = "Número de Hijos",
    y = "Frecuencia Relativa"
  ) +
  coord_cartesian(ylim = y_limits) +  
  theme_minimal()

p_numhijos_otro_pais <- ggplot(df_otro_pais, aes(x = NHIJOS, y = RelativeFrequency)) +
  geom_bar(stat = "identity", fill = "red") +
  labs(
    title = "Número de hijos (Otro país)",
    x = "Número de Hijos",
    y = "Frecuencia Relativa"
  ) +
  coord_cartesian(ylim = y_limits) +  
  theme_minimal()


grid.arrange(p_numhijos_espana, p_numhijos_otro_pais, ncol = 2)

```

```{r numhijos_by_nacionalidad_junto}
# Cálculo de frecuencias relativas para cada grupo

df_grouped <- df %>%
  group_by(NACIM, NHIJOS) %>%
  summarize(RelativeFrequency = n() / nrow(df[df$NACIM == NACIM, ]))

# Gráfico conjunto

p_numhijos_merged <- ggplot(df_grouped, aes(x = NHIJOS, y = RelativeFrequency, fill = NACIM)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(
    title = "Distribución del número de hijos por nacionalidad",
    x = "Número de Hijos",
    y = "Frecuencia Relativa"
  ) +
  scale_fill_manual(values = c("España" = "blue", "Otro país" = "red")) +
  theme_minimal()

p_numhijos_merged
```

```{r numhijos_by_nacionalidad_boxplot}
p_boxplot_nacim <- ggplot(df, aes(x = NACIM, y = NHIJOS, fill = NACIM)) +
  geom_boxplot(coef = 1.5, outlier.colour = "orange") +
  labs(
    title = "Número de hijos por nacionalidad",
    x = "Nacionalidad",
    y = "Número de hijos"
  ) +
  scale_fill_manual(values = c("España" = "blue", "Otro país" = "red")) +
  theme_minimal()

p_boxplot_nacim
```
Podemos observar que hay múltiples outliers, como consecuencia de que la inmensa mayoría de la gente suele estar dentro del rango intercuartílico para el número de hijos, siendo muy raro tener 6 hijos o más. Un tratamiento más riguroso para detectar las anomalías se realizará posteriormente.


```{r anadir_luego}
df %>%
  filter(is.na(NHIJOS) & HIJOS == "Sí")

df %>%
  filter(!is.na(NHIJOS) & HIJOS == "No")
```

Nota: meter mapa por provincias.



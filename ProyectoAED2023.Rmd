---
title: Mini Proyecto de Análisis Exploratorio de Datos
author:
  - name: Nicolás Camañes Antolín
  - name: Rubén Castillo Carrasco
  - name: Erik González Soler
  - name: Jesús Martínez Leal

# document options
journal: notspecified
type: article

# front matter
simplesummary: |
  En este proyecto de Análisis Exploratorio de Datos se explora un conjunto de datos real con el fin de obtener valiosas perspectivas y conclusiones.
abstract: |
  
  A single paragraph of about 200 words maximum. For research articles, 
  abstracts should give a pertinent overview of the work. We strongly encourage
  authors to use the following style of structured abstracts, but without 
  headings: 1) Background: Place the question addressed in a broad context and
  highlight the purpose of the study; 2) Methods: Describe briefly the main
  methods or treatments applied; 3) Results: Summarize the article's main 
  findings; and 4) Conclusion: Indicate the main conclusions or interpretations. 
  The abstract should be an objective representation of the article, it must not 
  contain results which are not presented and substantiated in the main text and 
  should not exaggerate the main conclusions.
  
# back matter
keywords: |
  Análisis exploratorio de datos; Patrones en datos; Encuesta de población; Limpieza de datos
acknowledgement: |
  Es necesario mostrar nuestro agradecimiento a ValgrAI por el apoyo en el pago de la matrícula para el Máster en Ciencia de Datos (UV). Además, no nos podemos olvidar del profesorado que nos permitirá formarnos en este ámbito.
authorcontributions: |
  Aquí tenemos que poner más o menos lo que ha participado cada uno.
abbreviations:
  - short: AED
    long: Análisis Exploratorio de Datos
    
bibliography: mybibfile.bib
appendix: appendix.tex
endnotes: false
output: 
  rticles::mdpi_article:
    extra_dependencies: longtable
---

# Introducción.

El conjunto de datos que se utiliza para el análisis pertenece al Instituto Nacional de Estadística (INE). En concreto, pertenece a una encuesta realizada a la población en el año 2021 que tiene como propósito el proporcionar información detallada sobre personas, viviendas y edificios que no puede obtenerse a través de registros administrativos. En nuestro caso, hemos decidido hacer la exploración en su mayoría de la parte relacionada a cuestiones que se les hizo a adultos (personas de 16 años o más). Para agregar más variables de interés se escogieron algunas de otro conjunto de datos, también de esta encuesta, hecho a todos los integrantes de la vivienda y no solo a adultos. El enlace a los ficheros de microdatos está presente [aquí](https://www.ine.es/dyngs/INEbase/es/operacion.htm?c=Estadistica_C&cid=1254736177092&menu=resultados&idp=1254735572981#!tabs-1254736195790).

## Carga de librerías y datos necesarios para el análisis

```{r setup, cache = F, echo = F, message = F, warning = F, tidy = F}
# Configuración general de chunks
library(knitr)
options(width = 100)
knitr::opts_chunk$set(echo = F, message = F, error = F, warning = F, comment = NA, dpi = 100, tidy = F, cache.path = '.cache/', fig.path = './figure/', include = F)
```

Como es habitual, cargamos las librerías que necesitamos al inicio del documento.

```{r librerias, message = F, include = T, echo = F}
# Carga de librerías necesarias con pacman
library(pacman)
pacman::p_load(readr, stringr, tidyr, dplyr, readxl, ggplot2, forcats, haven, kableExtra, VIM)
```

Pasamos ahora a hacer la carga del conjunto de datos, presentado tanto en .txt como .csv en la carpeta *data* incluida en el repositorio del proyecto. Asimismo, cargamos el fichero .xlsx que nos muestra el *Diseño de registro y valores válidos de las variables*. Este fichero nos será especialmente útil puesto que permitirá una automatización para convertir nuestra *Raw data* a *Technically correct data*, teniendo cada variable su tipo correcto.

```{r extraccion_dataset_csv}
ruta_csv <- "data/ECEPOVadultos_2021.csv"
df_1 <- read_delim("data/ECEPOVadultos_2021.csv", 
    delim = "\t", escape_double = FALSE, 
    col_types = cols(ESTUDIOS = col_double(), 
        CAMPO = col_double()), trim_ws = TRUE)
```

```{r lectura_dataset_readLines, eval = FALSE}
ruta_txt <- "./data/md_ECEPOVadultos_2021.txt"
lines <- readLines(ruta_txt)

# Función para sacar las subcadenas en cada línea del .txt

extract_substrings <- function(line, start_position, length) {
  substrings <- character(length(start_position))
  
  for (i in seq_along(start_position)) {
    start <- start_position[i]
    end <- start + length[i] - 1
    substrings[i] <- substr(line, start, end)
  }
  
  return(substrings)
}

# Guardaremos las substrings en una matriz por eficiencia computacional

num_lines <- length(lines)
num_variables <- length(excel_info_1$Variable)
substring_matrix <- matrix("", nrow = num_lines, ncol = num_variables)

# Extraer las subcadenas para todas las líneas y guardarlas en las filas de la matriz

for (i in 1:num_lines) {
  substring_matrix[i, ] <- extract_substrings(lines[i], excel_info_1$Posición, excel_info_1$Longitud)
}

# Conversión al dataframe desde la matriz

df_1 <- as.data.frame(substring_matrix)
colnames(df_1) <- excel_info_1$Variable

```

```{r lectura_diseno}
ruta_excel <- "data/dr_ECEPOVadultos_2021.xlsx"
excel_info_1 <- read_excel(ruta_excel, sheet = "Diseño", range = "A2:H50", col_names = TRUE)

# Almacenamiento de distintas hojas del excel para optimizar el código
Tablas1 <- read_excel(ruta_excel, sheet = "Tablas1", range = "A4:C63", col_names = TRUE)
Tablas2 <- read_excel(ruta_excel, sheet = "Tablas2", range = "A4:C112", col_names = TRUE)
Tablas3 <- read_excel(ruta_excel, sheet = "Tablas3", range = "A4:C48", col_names = TRUE)
```


A pesar de que fue de gran utilidad el fichero que ofrecía INE para la transformación de las variables a un tipo correcto, aparecieron algunos fallos que tuvimos que solventar de manera manual. Determinadas variables no fueron bien codificadas por parte de INE, de tal forma que hubo que modificar ligeramente el fichero .xlsx. Concretamente, fue en algunos *diccionarios* de variables en los que no terminaba de estar correctamente bien determinado el *código* (lo que sería el level en un factor). El error presentado (en algunas variables) consistía, básicamente, en que aparecía "01" en lugar de "1" (para otros números similar), valor recogido en las observaciones.

```{r conversion_dataset}
# Cambio manual por datos mal introducidos "2 " --> "2" para la posterior lectura con el diccionario

manual_change <- c("ESTUDIOS", "CAMPO", "NDESPLA", "MTRANSPOR_1", "MTRANSPOR_2")

df_1 <- df_1 %>%
  mutate(across(all_of(manual_change), ~ str_remove_all(., " ")))

# Conversión de las variables correspondientes a tipo numérico según indica INE

dic_tipo <- excel_info_1$Tipo

df_1 <- df_1 %>%
  mutate(across(which(dic_tipo == "N"), as.numeric)) %>%
  mutate()

# Transformación a factores de las variables pertinentes usando el fichero que ofrece INE

excel_dic <- excel_info_1 %>%
  filter(!is.na(`Diccionario de la variable`))

dic_vars <- excel_dic$Variable
dic_var <- excel_dic$`Diccionario de la variable`
dic_table <- excel_dic$`Diccionario ubicado en la hoja…`

## bucle donde se irán convirtiendo a factor de manera iterativa aquellas variables que nos indique el fichero del INE

for (i in seq_along(dic_vars)) {
  
  dataframe_name <- dic_table[i]  
  df_table <- get(dataframe_name)
  positions <- which(df_table == dic_var[i], arr.ind = TRUE) # obtener posición donde se encuentra la palabra del diccionario 
  
  if (length(positions) > 0) {
    
    fila_start <- positions[1]
    columna_start <- positions[2]
    
    fila_end <- min(which(is.na(df_table[(fila_start + 2):nrow(df_table), columna_start]), arr.ind = TRUE)[1]) + fila_start

    levels <- df_table[(fila_start + 2):fila_end, columna_start]
    labels <- df_table[(fila_start + 2):fila_end, columna_start + 1]
    
    # conversión a tipo vector para aplicar debajo factor()
    levels <- unlist(levels[[1]])
    labels <- unlist(labels[[1]])
  }
  
  df_1 <- df_1 %>%
      mutate_at(vars(dic_vars[i]), ~factor(., levels = levels, labels = labels)) 
}
```

Una vez está hecha la conversión del dataset que contaba con un mayor número de variables procedemos a hacer una unión con el otro mencionado anteriormente, solo utilizando algunas variables de interés como SEXO o EDAD.


```{r seleccion_columnas}
columnas_a_leer <- c("IDEN", "NPV", "FACTOR", "SEXO", "EDAD", "NACIM", "PNACIM")
df_2 <- read_dta("./data/ECEPOVhogar_2021.dta", col_select = columnas_a_leer)
```

Las variables SEXO, NACIM y PNACIM de este nuevo dataset deben ser convertidas a sus tipos correctos, por lo que se hace uso de la información que proporciona INE sobre las variables.

```{r lectura_diseno_2}
ruta_excel_2 <- "data/dr_ECEPOVhogar_2021.xlsx"
excel_info_2 <- read_excel(ruta_excel_2, sheet = "Diseño", range = "A2:H162", col_names = TRUE)

# Cogemos los diccionarios manualmente puesto que solo tenemos 3 variables y el proceso es más eficiente en lectura

T_SEXO <- read_excel(ruta_excel_2, sheet = "Tablas2", range = "A6:B8", col_names = TRUE)
T_NACIM <- read_excel(ruta_excel_2, sheet = "Tablas2", range = "A26:B28", col_names = TRUE)
T_PAIS <- read_excel(ruta_excel_2, sheet = "Tablas1", range = "A74:B276", col_names = TRUE)
```

```{r conversion_dataset_2}
df_2 <- df_2 %>%
  mutate(SEXO = factor(SEXO, levels = T_SEXO$Código, labels = T_SEXO$Descripción)) %>%
  mutate(NACIM = factor(NACIM, levels = T_NACIM$Código, labels = T_NACIM$Descripción)) %>%
  mutate(PNACIM = factor(PNACIM, levels = T_PAIS$Código, labels = T_PAIS$Descripción))
```

Hacemos el merge utilizando las variables de identificación IDEN, NPV y FACTOR, de tal manera que podamos establecer una relación unívoca entre los adultos presentes en el primer y segundo dataset.

```{r union_datasets}
df_merged <- merge(df_1, df_2[, c("IDEN", "NPV", "FACTOR", "EDAD", "SEXO", "NACIM", "PNACIM")], by = c("IDEN", "NPV", "FACTOR"), all.x = TRUE)
```

## Resumen de los datos

Podemos hacernos una idea rápida bastante completa de cómo son los datos pertenecientes a nuestro dataframe, *df*, haciendo uso de la función glimpse, perteneciente a la librería dplyr. 

```{r glimpse}
dplyr::glimpse(df_merged, width = 60)
```

Observamos que es un dataset con total de 361934 observaciones y con 52 variables, lo cual es mucho más de lo que necesitaremos.

Tras un análisis de las variables en *dr_ECEPOVadultos_2021.xlsx* y 
*dr_ECEPOVhogar_2021.xlsx*, consideramos que muchas de las variables no nos otorgarán interés para el análisis que particularmente nosotros deseamos aplicar, por lo que seleccionaremos aquellas relevantes.


```{r variables_usadas, include = T}
data_info <- data.frame(
  Variable = c(
    "IDQ_PV", "TAM_MUNI", "EC", "EDADEC", "ESTUDIOS", "ANOESTUD",
    "EDADESTUD", "CAMPO", "SITLAB", "SATISTIEMP", "COMPRAINT", "HIJOS",
    "NHIJOS", "TDOMEST", "SEXO", "EDAD", "NACIM", "PNACIM"
  ),
  Descripción = c(
    "Código de la provincia de residencia.",
    "Tamaño del municipio.",
    "Estado civil legal.",
    "Edad de adquisición del estado civil legal.",
    "Nivel de estudios alcanzado.",
    "Año que alcanzó su mayor nivel de estudios.",
    "Edad a la que alcanzó su mayor nivel de estudios.",
    "Campo de los estudios.",
    "Situación laboral durante la última semana.",
    "Grado de satisfacción en el tiempo de desplazamiento al trabajo.",
    "Realización de compras por internet en el último mes.",
    "Tenencia de hijos.",
    "Número total de hijos.",
    "Grado de participación en las tareas domésticas del hogar.",
    "Sexo de la persona.",
    "Edad de la persona.",
    "Lugar de nacimiento de la persona (España u otro sitio).",
    "País de nacimiento exacto de la persona."
  )
)

knitr::kable(data_info, format = "latex",
             booktabs = TRUE, 
             caption = "Variables de interés para el estudio.", 
             align = 'ccc', centering = FALSE,
             table.envir = "table", position = "H")
```

```{r seleccion_variables}
var_interes <- c("IDQ_PV", "TAM_MUNI", "SEXO", "EDAD", "NACIM", "PNACIM", "EC", "EDADEC", "ESTUDIOS", "ANOESTUD", "EDADESTUD", "CAMPO", "SITLAB", "SATISTIEMP", "COMPRAINT", "NHIJOS", "HIJOS", "TDOMEST")
  
df <- df_merged %>%
  select(var_interes)
```

```{r glimpse_reducido}
glimpse(df, width = 60)
```

Seguidamente, mediante la función *summary* obtenemos información acerca de las características de cada columna del dataset.

```{r summary}
summary(df)
```

Una modificación de la función summary que incluye algo menos de información, pero que nos será útil al no haber tanta saturación aparece a continuación.

```{r funcion_sumario, include = FALSE}

SumarioDatos <- function(data = data, digitos = 3, max_topLevel_length = 47) {
  type <- sapply(data, class)
  levels <- sapply(data, function(x) { length(unique(x)) })
  topLevel <- sapply(data, function(x) {
    t <- table(x)
    colnames(t(which.max(t)))
  })

  # Truncate topLevel and add "..." if it exceeds the maximum length
  topLevel <- ifelse(nchar(topLevel) > max_topLevel_length, paste0(substr(topLevel, 1, max_topLevel_length - 3), "..."), topLevel)

  topCount <- sapply(data, function(x) { max(table(x)) })
  topFrac <- sapply(data, function(x, digitos) {
    t <- table(x)
    (max(t) / sum(t))
  }) %>% round(digits = digitos)

  missFrac <- sapply(data, function(x) { sum(is.na(x) == TRUE) / length(x) }) %>%
    round(digits = digitos)

  sumario <- data.frame(
    variable = colnames(data),
    type = type,
    levels = levels,
    topLevel = topLevel,
    topCount = topCount,
    topFrac = topFrac,
    missFrac = missFrac
  )

  rownames(sumario) <- NULL
  return(sumario)
}
```

```{r kable_sumario, include = T}
kable_res <- knitr::kable(SumarioDatos(data = df), format = "latex",
             booktabs = TRUE, 
             caption = "Información relevante acerca de las variables de estudio.", 
             align = 'ccc', centering = FALSE,
             table.envir = "table", position = "H",
             tabular.environment = "tabularx")

kable_styling(kable_res, font_size = 7, position = "left" )
```

## Datos faltantes

Una representación precisa de cómo se distribuyen los *missing values* por nuestro conjunto de datos lo otorga la librería *VIM* con la función *aggr*. Puede observarse 

```{r missing_values, include = T, fig.width = 5.9, fig.height = 4, fig.align = "left"}
df %>%
  select_if(~ anyNA(.)) %>%
  aggr(prop = TRUE, numbers = TRUE, sortVars = TRUE, sortCombs = TRUE, cex.axis = 0.6, cex.lab = 0.7, digits = 1, gap = 2, cex.numbers = 0.6)
```


Nota: meter mapa por provincias.


```{comment}
If the documentclass option "submit" is chosen, please insert a blank line before and after any math environment (equation and eqnarray environments). This ensures correct linenumbering. The blank line should be removed when the documentclass option is changed to "accept" because the text following an equation should not be a new paragraph.
```

